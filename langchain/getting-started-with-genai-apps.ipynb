{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "## Langsmith tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1158cc890>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x115557110>, root_client=<openai.OpenAI object at 0x115e54650>, root_async_client=<openai.AsyncOpenAI object at 0x115eb6f50>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\"What is generative AI?\").content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI refers to a category of artificial intelligence systems designed to generate content that is often indistinguishable from content created by humans. This technology leverages machine learning models, particularly neural networks, to produce text, images, music, and other types of data. The most notable advancements in generative AI have been driven by deep learning techniques such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models like GPT (Generative Pre-trained Transformer).\\n\\nGenerative AI has a wide range of applications, including:\\n\\n1. **Content Creation**: Automatically generating written content, such as articles, stories, and poetry.\\n2. **Art and Design**: Creating original artwork or assisting in design processes.\\n3. **Music Composition**: Composing music or generating new sounds.\\n4. **Gaming**: Creating characters, levels, or even narrative elements in video games.\\n5. **Data Augmentation**: Enhancing training datasets for machine learning by creating synthetic data.\\n6. **Chatbots and Virtual Assistants**: Powering conversational agents with natural language capabilities.\\n\\nWhile generative AI presents exciting possibilities, it also raises ethical considerations, such as the potential for creating misleading information, deepfakes, and issues related to copyright and ownership of AI-generated content.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt template\n",
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a tool or platform associated with LangChain, which is designed to assist developers in building and deploying applications that utilize large language models (LLMs). It provides a suite of features aimed at improving the development workflow, including the ability to trace, test, and evaluate LLM applications more effectively.\\n\\nKey features of Langsmith include:\\n\\n1. **Tracing:** Langsmith allows developers to trace the execution of their language model applications. This helps in understanding how data flows through the application and identifying any issues in the processing pipeline.\\n\\n2. **Testing:** It provides tools to rigorously test LLM applications, ensuring that they perform as expected under various conditions and inputs.\\n\\n3. **Evaluation:** Langsmith offers capabilities for evaluating the performance and output quality of language models. This can include metrics for accuracy, relevance, and other criteria important to the application's success.\\n\\nOverall, Langsmith aims to streamline the development process for LLM-based applications, making it easier for developers to create robust, high-quality language-driven solutions.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 204, 'prompt_tokens': 33, 'total_tokens': 237, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_703d4ff298', 'finish_reason': 'stop', 'logprobs': None} id='run-86597b46-0001-4dd3-87e3-3c8a985dab0e-0' usage_metadata={'input_tokens': 33, 'output_tokens': 204, 'total_tokens': 237, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain\n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a toolkit designed for developers working with language models, providing essential tools for debugging, testing, evaluating, and monitoring AI applications. It offers features like tracing, version comparisons, and feedback analysis to help developers optimize and understand their language model implementations better. Langsmith is particularly useful for ensuring that AI applications are functioning as intended and for making iterative improvements based on detailed insights and analytics.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
